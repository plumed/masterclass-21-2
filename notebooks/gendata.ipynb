{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLUMED masterclass 21.2: Statistical errors in MD (data generation)\n",
    "\n",
    "## Initial notes\n",
    "\n",
    "The data contained in the files <i>uncorrelated_data</i>, <i>correlated_data</i> and <i>weighted_data</i> was generated by sampling from known statistical models.  For those who are interested I have included the python code that I used to generate the data in this notebook.  Please note that the codes in the cells below generate (pseudo) random numbers.  If you run these cells you will thus not get the same list of data points that are in <i>uncorrelated_data</i>, <i>correlated_data</i> and <i>weighted_data</i> that you downloaded from GitHub.\n",
    "\n",
    "### Uncorrelate data \n",
    "\n",
    "The uncorrelated data are all samples from a normal random variable with $\\mu=0$ and $\\sigma=1$.  The data is generated as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"../data/uncorrelated_data\", \"w\")\n",
    "\n",
    "f.write(\"#! FIELDS time rand \\n\")\n",
    "for i in range(0,10001):\n",
    "    f.write(str(i) + \" \"  + str( np.random.normal(0,1) ) + \"\\n\" )\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlated data\n",
    "\n",
    "The correlated data is generated by running the following script.  You can see that the previous random variable in the time series is used when generating the next variable.  The data points are thus clearly correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"../data/correlated_data\", \"w\")\n",
    "\n",
    "prev = 0.;\n",
    "f.write(\"#! FIELDS time rand \\n\")\n",
    "for i in range(0,10001):\n",
    "    new = 0.95*prev + 2*np.random.uniform(0,1) - 1\n",
    "    f.write( str(i) + \" \" + str(new/2. + 0.5) + \"\\n\" )\n",
    "    prev = new\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data with weights\n",
    "\n",
    "The weighted data is generated by generating normal random variables with $\\mu=0.6$ and $\\sigma=0.25$.  In the exercise we suppose that the following bias potential is acting on the data:\n",
    "\n",
    "$$\n",
    "V(x) = \\frac{1}{2} 4(x-0.6)^2\n",
    "$$\n",
    "\n",
    "Our reweighting weights counteract the effect of this bias.  We should thus see that the reweighted distribution for the CV approximately uniform.  Masterclass-21-3 explores the theory that this reweighting algorithm is based on in more detail. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"../data/weighted_data\", \"w\")\n",
    "\n",
    "n = 0\n",
    "f.write(\"#! FIELDS time rand \\n\")\n",
    "while True :\n",
    "    x = np.random.normal( 0.6, 0.5 )\n",
    "    if (x>=0) & (x<=1) :\n",
    "        f.write(str(n) + \" \" + str(x) + \"\\n\")\n",
    "        n = n + 1\n",
    "    if n==10001 : break \n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
